# Image Preprocessing Pipeline: 400ร300 โ [432, 1536]

## ๐ฏ **Question: How is a 400ร300 image converted to [432, 1536]?**

---

## ๐ **Complete Preprocessing Pipeline**

```
Original Image (400ร300 RGB)
    โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ STEP 1: Resize to Patch-Aligned Dimensions                      โ
โ โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ                                                                  โ
โ Goal: Make dimensions divisible by patch_size (16)              โ
โ                                                                  โ
โ Calculation:                                                     โ
โ   - Target grid: 18ร24 patches                                  โ
โ   - Height: 18 patches ร 16 pixels/patch = 288 pixels          โ
โ   - Width:  24 patches ร 16 pixels/patch = 384 pixels          โ
โ                                                                  โ
โ Input:  400ร300ร3                                               โ
โ Output: 288ร384ร3                                               โ
โโโโโโโโโโโโโโโโโโโโฌโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
                   โ
                   โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ STEP 2: Add Temporal Dimension                                  โ
โ โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ                                                                  โ
โ Qwen3-VL uses temporal_patch_size=2 for video support          โ
โ For static images, duplicate the frame                          โ
โ                                                                  โ
โ Input:  [1, 3, 288, 384]    (T, C, H, W)                       โ
โ Output: [2, 3, 288, 384]    (duplicate frame for temporal=2)   โ
โโโโโโโโโโโโโโโโโโโโฌโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
                   โ
                   โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ STEP 3: Create 3D Patches                                       โ
โ โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ                                                                  โ
โ Split into patches of size:                                     โ
โ   temporal_patch_size ร patch_size ร patch_size                โ
โ   = 2 ร 16 ร 16                                                 โ
โ                                                                  โ
โ Number of patches:                                              โ
โ   T: 2 รท 2 = 1 temporal patch                                  โ
โ   H: 288 รท 16 = 18 height patches                              โ
โ   W: 384 รท 16 = 24 width patches                               โ
โ   Total: 1 ร 18 ร 24 = 432 patches                             โ
โ                                                                  โ
โ Each patch contains:                                            โ
โ   2 (temporal) ร 16 (height) ร 16 (width) ร 3 (RGB)            โ
โ   = 1536 values                                                 โ
โ                                                                  โ
โ Input:  [2, 3, 288, 384]                                        โ
โ Output: [432, 2, 16, 16, 3]  (conceptual)                      โ
โโโโโโโโโโโโโโโโโโโโฌโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
                   โ
                   โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ STEP 4: Flatten Each Patch                                      โ
โ โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ                                                                  โ
โ Flatten the last 4 dimensions: [2, 16, 16, 3] โ [1536]         โ
โ                                                                  โ
โ Input:  [432, 2, 16, 16, 3]                                     โ
โ Output: [432, 1536]  โ This is the input to PatchEmbed!        โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
```

---

## ๐ข **Detailed Calculation**

### Original Image
```
Shape: 400 ร 300 ร 3 (RGB)
Pixels: 400 ร 300 = 120,000 pixels
Total values: 120,000 ร 3 = 360,000 values
```

### After Resize (Step 1)
```
Shape: 288 ร 384 ร 3
Pixels: 288 ร 384 = 110,592 pixels
Total values: 110,592 ร 3 = 331,776 values

Why these dimensions?
  - Must be divisible by patch_size (16)
  - Aspect ratio preserved approximately: 384/288 = 1.33, 400/300 = 1.33 โ
```

### After Temporal Duplication (Step 2)
```
Shape: 2 ร 3 ร 288 ร 384
Total values: 2 ร 331,776 = 663,552 values
```

### After Patching (Step 3)
```
Number of patches:
  Temporal: 2 รท temporal_patch_size(2) = 1
  Height:   288 รท patch_size(16) = 18
  Width:    384 รท patch_size(16) = 24
  Total:    1 ร 18 ร 24 = 432 patches

Each patch size:
  2 ร 16 ร 16 ร 3 = 1536 values

Shape: [432, 2, 16, 16, 3]
```

### After Flattening (Step 4)
```
Shape: [432, 1536]
Total values: 432 ร 1536 = 663,552 โ (matches step 2!)

This is the input to the vision model!
```

---

## ๐จ **Visual Representation**

### Image to Grid
```
Original Image (400ร300)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ                                โ
โ         400 pixels             โ
โ                                โ
โ  300 pixels                    โ
โ                                โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

           โ Resize

Patch-Aligned Image (288ร384)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ  [16] [16] [16] ... [16]  (24 patches) โ
โ  [16] [16] [16] ... [16]               โ
โ   ...                                   โ  18 patches
โ  [16] [16] [16] ... [16]               โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

           โ Add temporal + Patch

432 Patches (18ร24ร1)
Each patch: [2, 16, 16, 3] = 1536 values
```

### Patch Structure
```
One 3D Patch:
โโโโโโโโโโโโโโโโโโโ
โ  Frame 1        โ  16ร16ร3 = 768 values
โ  โโโโโโโโโโโโโ  โ
โ  โ 16ร16 RGB โ  โ
โ  โโโโโโโโโโโโโ  โ
โโโโโโโโโโโโโโโโโโโค
โ  Frame 2        โ  16ร16ร3 = 768 values
โ  โโโโโโโโโโโโโ  โ
โ  โ 16ร16 RGB โ  โ
โ  โโโโโโโโโโโโโ  โ
โโโโโโโโโโโโโโโโโโโ
Total: 2ร768 = 1536 values per patch
```

---

## ๐ป **Code Implementation**

### Processor Code (Conceptual)
```python
from transformers import AutoProcessor
from PIL import Image

# Load processor
processor = AutoProcessor.from_pretrained("Qwen/Qwen3-VL-4B-Instruct")

# Load image
image = Image.open("test_image.jpg")  # 400ร300

# Process image
inputs = processor(
    images=[image],
    return_tensors="pt"
)

# Check shapes
print(f"pixel_values: {inputs['pixel_values'].shape}")
# Output: torch.Size([432, 1536])

print(f"image_grid_thw: {inputs['image_grid_thw']}")
# Output: tensor([[1, 18, 24]])
```

### What the Processor Does
```python
def process_image(image):
    # Step 1: Resize to patch-aligned dimensions
    # Target: make H and W divisible by 16
    image = smart_resize(image)  # 400ร300 โ 288ร384
    
    # Step 2: Convert to tensor and add temporal dimension
    # [C, H, W] โ [T, C, H, W]
    image = to_tensor(image)  # [3, 288, 384]
    image = image.unsqueeze(0)  # [1, 3, 288, 384]
    image = image.repeat(2, 1, 1, 1)  # [2, 3, 288, 384] (duplicate for temporal=2)
    
    # Step 3: Create 3D patches
    # [T, C, H, W] โ [num_patches, T_patch, H_patch, W_patch, C]
    patches = create_3d_patches(
        image,
        temporal_patch_size=2,  # 2 frames โ 1 temporal patch
        patch_size=16           # 16ร16 spatial patches
    )  # [432, 2, 16, 16, 3]
    
    # Step 4: Flatten each patch
    # [432, 2, 16, 16, 3] โ [432, 1536]
    flattened = patches.reshape(432, -1)
    
    return flattened, grid_thw=[1, 18, 24]
```

---

## ๐ **Why These Numbers?**

### Why 432 patches?
```
Grid: 18 ร 24 = 432 spatial locations
Temporal: 1 (after grouping 2 frames into 1 temporal patch)
Total: 432 patches
```

### Why 1536 dimensions per patch?
```
temporal_patch_size ร patch_size ร patch_size ร channels
= 2 ร 16 ร 16 ร 3
= 1536
```

### Why temporal_patch_size = 2?
```
Qwen3-VL is designed for both images AND videos
- For videos: groups 2 consecutive frames
- For images: duplicates the single frame to create 2 frames
- Provides temporal consistency in the architecture
```

### Why grid_thw = [1, 18, 24]?
```
T (temporal): 1 temporal patch (after grouping 2 frames)
H (height):   18 spatial patches (288 รท 16)
W (width):    24 spatial patches (384 รท 16)
```

---

## ๐ **Connection to Vision Model**

After preprocessing, the vision model receives:

```
Input to Qwen3VLVisionModel.forward():
  pixel_values:  [432, 1536]
  grid_thw:      [[1, 18, 24]]

Step in Vision Model:
  1. PatchEmbed (Conv3D):
     Input:  [432, 1536]
     Reshape to: [-1, 3, 2, 16, 16]  (restore 3D patch structure)
     Conv3D: kernel=[2, 16, 16], stride=[2, 16, 16]
     Output: [432, 1024]  (embedded patches)
```

---

## ๐ **Shape Summary Table**

| Stage | Shape | Description |
|-------|-------|-------------|
| **Original** | `[400, 300, 3]` | Input image (HรWรC) |
| **Resize** | `[288, 384, 3]` | Patch-aligned (divisible by 16) |
| **Add Temporal** | `[2, 3, 288, 384]` | Duplicate frame (TรCรHรW) |
| **Patch** | `[432, 2, 16, 16, 3]` | 3D patches |
| **Flatten** | `[432, 1536]` | **Input to vision model** |
| **PatchEmbed** | `[432, 1024]` | Embedded patches |
| **After 24 Blocks** | `[432, 1024]` | Transformer output |
| **PatchMerger** | `[108, 2560]` | Spatial merge + project to text dim |

---

## ๐ฏ **Key Takeaways**

1. **400ร300 is resized to 288ร384** to be divisible by patch_size (16)
2. **Temporal dimension added**: Single frame duplicated โ 2 frames
3. **432 patches created**: 18ร24 spatial grid, 1 temporal group
4. **1536 values per patch**: 2 (temporal) ร 16 ร 16 (spatial) ร 3 (RGB)
5. **Final input shape**: [432, 1536] ready for vision model

The key insight is that Qwen3-VL treats **even static images as 2-frame sequences** to maintain consistency with its video processing architecture!

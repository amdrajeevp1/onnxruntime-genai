# Qwen3-VL Vision Model - Quick Reference

## ğŸ“Š **Simplified Dataflow (Example: 400Ã—300 Image)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT                                         â”‚
â”‚  pixel_values: [432, 1536]  (flattened 18Ã—24 patches)          â”‚
â”‚  grid_thw:     [1, 18, 24]  (1 frame, 18Ã—24 patches)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MODULE 1: PatchEmbed (Conv3D)                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  nn.Conv3d(3 â†’ 1024, kernel=[2,16,16], stride=[2,16,16])      â”‚
â”‚                                                                  â”‚
â”‚  [432, 1536] â†’ reshape â†’ [-1, 3, 2, 16, 16]                    â”‚
â”‚              â†’ conv3d  â†’ [-1, 1024, 1, 1, 1]                    â”‚
â”‚              â†’ flatten â†’ [432, 1024]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MODULE 2: Position Embeddings                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  Bilinear interpolation from 48Ã—48 learned grid                â”‚
â”‚  Permute for spatial merging                                    â”‚
â”‚                                                                  â”‚
â”‚  [432, 1024] + pos_embeds â†’ [432, 1024]                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MODULE 3: Rotary Position Embeddings                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  Compute (cos, sin) for each patch position                    â”‚
â”‚                                                                  â”‚
â”‚  grid_thw â†’ compute (row,col) â†’ [432, 128] cos, sin            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
         â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
         â•‘   24 Transformer Blocks         â•‘
         â•‘   Each block:                   â•‘
         â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
         â•‘   â”‚ LayerNorm                â”‚  â•‘
         â•‘   â”‚ Attention (with rotary)  â”‚  â•‘
         â•‘   â”‚ Residual                 â”‚  â•‘
         â•‘   â”‚ LayerNorm                â”‚  â•‘
         â•‘   â”‚ MLP (1024â†’4096â†’1024)     â”‚  â•‘
         â•‘   â”‚ Residual                 â”‚  â•‘
         â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
         â•‘                                  â•‘
         â•‘   [432, 1024] â†’ [432, 1024]     â•‘
         â•‘                                  â•‘
         â•‘   DeepStack: Save features at   â•‘
         â•‘   layers 5, 11, 17              â•‘
         â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MODULE 5: PatchMerger                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  Spatial merge (2Ã—2 â†’ 1) + Project to text dimension           â”‚
â”‚                                                                  â”‚
â”‚  [432, 1024] â†’ view([108, 4096])  (merge 2Ã—2 patches)          â”‚
â”‚              â†’ LayerNorm                                        â”‚
â”‚              â†’ Linear(4096 â†’ 4096) + GELU                       â”‚
â”‚              â†’ Linear(4096 â†’ 2560)                              â”‚
â”‚              â†’ [108, 2560]                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OUTPUT                                        â”‚
â”‚  last_hidden_state:  [432, 1024]   (raw patches)               â”‚
â”‚  pooler_output:      [108, 2560]   (MERGED, ready for text!)   â”‚
â”‚  deepstack_features: [[108,2560], [108,2560], [108,2560]]      â”‚
â”‚                       (from layers 5, 11, 17)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¢ **Shape Transformations at a Glance**

| Module | Input Shape | Output Shape | Key Operation |
|--------|-------------|--------------|---------------|
| PatchEmbed | [432, 1536] | [432, 1024] | Conv3D projection |
| Pos Embed | [432, 1024] | [432, 1024] | Add interpolated positions |
| Rotary | grid_thw | cos/sin [432, 128] | Compute rotation matrices |
| 24 Blocks | [432, 1024] | [432, 1024] | Attention + MLP |
| PatchMerger | [432, 1024] | [108, 2560] | **2Ã—2 merge + project** |

---

## ğŸ¯ **Critical Points**

### 1. **Patch Count Math**
```
Image: 400Ã—300 â†’ Resized to 288Ã—384
Patches: 288Ã·16 Ã— 384Ã·16 = 18Ã—24 = 432 patches
After merge: 9Ã—12 = 108 patches (4Ã— reduction)
```

### 2. **Dimension Matching**
```
Vision hidden:  1024
Text hidden:    2560
Merger output:  2560  â† Matches text!
```

### 3. **Attention Details**
```
QKV Linear:  [432, 1024] â†’ [432, 3072]
Split Q/K/V: [432, 3072] â†’ 3 Ã— [432, 16, 64]
Attn output: [1, 16, 432, 64] â†’ [432, 1024]
```

### 4. **Spatial Merging Strategy**
```
Position embedding permutation PREPARES for merge:
  [T, H, W, hidden] â†’ [T, H/2, 2, W/2, 2, hidden]
  
PatchMerger EXECUTES the merge:
  [432, 1024] â†’ view([108, 4*1024]) â†’ [108, 4096]
              â†’ project â†’ [108, 2560]
```

---

## ğŸ”— **Connection to Text Model**

```
Vision Model Output:
  pooler_output: [108, 2560]
         â†“
Text Tokenizer creates:
  [1, 2, 3, <img>, <img>, ..., <img>, 4, 5, 6]
            â””â”€â”€â”€â”€ 108 tokens â”€â”€â”€â”€â”€â”˜
         â†“
Embedding Layer:
  [batch, seq_len, 2560]
  All tokens get embeddings, including <img> tokens
         â†“
Vision Injection (masked_scatter):
  Replace <img> token embeddings with vision features
  inputs_embeds[mask] = pooler_output  # [108, 2560]
         â†“
Merged Embeddings:
  [batch, seq_len, 2560]
  Now has REAL vision features instead of generic <img> embeddings!
         â†“
Text Decoder:
  Processes merged embeddings with full vision context
```

---

## ğŸ“ **Memory and Computation**

### Per-Image Memory (400Ã—300)
- **Hidden states**: 432 Ã— 1024 Ã— 4 bytes = **1.77 MB**
- **Attention weights**: 16 heads Ã— 432Â² Ã— 4 bytes = **12 MB**
- **Intermediate activations**: 432 Ã— 4096 Ã— 4 bytes = **7.08 MB**
- **Total per layer**: ~20 MB
- **Total for 24 layers**: ~480 MB

### Computation Complexity
- **Attention**: O(432Â²) = 186,624 operations per head
- **16 heads**: ~3M attention operations per layer
- **24 layers**: ~72M attention operations total
- **MLP**: 432 Ã— (1024 Ã— 4096 + 4096 Ã— 1024) = ~7B FLOPs per layer

---

## ğŸ¨ **Visual Representation**

```
Image (400Ã—300)
    â”‚
    â”œâ”€ Resize to patch-aligned (288Ã—384)
    â”‚
    â”œâ”€ Split into patches (18Ã—24 = 432)
    â”‚
    â”œâ”€ Conv3D â†’ Embeddings [432, 1024]
    â”‚
    â”œâ”€ + Position Embeddings
    â”‚
    â”œâ”€ Transformer Ã— 24 layers
    â”‚   â”‚
    â”‚   â”œâ”€ Self-Attention (with rotary)
    â”‚   â”œâ”€ MLP (1024â†’4096â†’1024)
    â”‚   â”‚
    â”‚   â””â”€ @ layers 5,11,17: Save DeepStack features
    â”‚
    â”œâ”€ Spatial Merge (2Ã—2 â†’ 1)
    â”‚   â”‚
    â”‚   â”œâ”€ 432 patches â†’ 108 merged patches
    â”‚   â””â”€ 4Ã—1024 â†’ 2560 (project to text dim)
    â”‚
    â””â”€ Output [108, 2560] â†’ Ready for text injection!
```

---

## ğŸ” **Module-by-Module Details**

### Module 1: PatchEmbed
- **Type**: `nn.Conv3d`
- **Params**: kernel=[2,16,16], stride=[2,16,16], bias=True
- **Purpose**: Extract patch features
- **Input**: Flattened patches [432, 1536]
- **Output**: Embeddings [432, 1024]

### Module 2: Position Embeddings
- **Type**: `nn.Embedding` + interpolation
- **Params**: 2304 learned positions (48Ã—48 grid)
- **Purpose**: Add spatial location info
- **Method**: Bilinear interpolation to image size

### Module 3: Rotary Embeddings
- **Type**: Custom computation
- **Params**: freq_table based on (row, col)
- **Purpose**: Relative position encoding for attention
- **Output**: cos/sin [432, 128] each

### Module 4: Transformer Block (Ã—24)
- **Components**:
  - LayerNorm [1024]
  - Attention [1024, num_heads=16]
  - LayerNorm [1024]
  - MLP [1024 â†’ 4096 â†’ 1024]

### Module 5: PatchMerger
- **Type**: LayerNorm + 2Ã— Linear
- **Params**: 
  - norm [4096]
  - fc1 [4096 â†’ 4096]
  - fc2 [4096 â†’ 2560]
- **Purpose**: Reduce patches & match text dim
- **Input**: [432, 1024]
- **Output**: [108, 2560]

---

## ğŸ“š **Quick Reference Card**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QWEN3-VL VISION MODEL CHEAT SHEET                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Config:                                                â”‚
â”‚   hidden_size: 1024                                    â”‚
â”‚   num_heads: 16                                        â”‚
â”‚   depth: 24                                            â”‚
â”‚   patch_size: 16                                       â”‚
â”‚   spatial_merge: 2                                     â”‚
â”‚   out_hidden: 2560                                     â”‚
â”‚                                                         â”‚
â”‚ Shapes (400Ã—300 image):                                â”‚
â”‚   Input:        [432, 1536]                            â”‚
â”‚   Patches:      [432, 1024]                            â”‚
â”‚   After blocks: [432, 1024]                            â”‚
â”‚   After merge:  [108, 2560] â† Ready for text!         â”‚
â”‚                                                         â”‚
â”‚ Key Operations:                                        â”‚
â”‚   1. Conv3D patch embedding                            â”‚
â”‚   2. Position interpolation                            â”‚
â”‚   3. 24Ã— Transformer (Attn + MLP)                      â”‚
â”‚   4. 2Ã—2 spatial merge                                 â”‚
â”‚   5. Project to text dimension (2560)                  â”‚
â”‚                                                         â”‚
â”‚ Output:                                                â”‚
â”‚   pooler_output: [108, 2560]                           â”‚
â”‚   â†’ Replaces 108 <|image_pad|> tokens in text!        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
